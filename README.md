# üß† An√°lisis de Suicidios en Antioquia (2007‚Äì2021) con PySpark

## üìò Descripci√≥n del proyecto

Este proyecto implementa un **proceso de an√°lisis batch** utilizando **Apache Spark (PySpark)** sobre el conjunto de datos p√∫blico de **suicidios reportados en el departamento de Antioquia entre los a√±os 2007 y 2021**, disponible en el portal de [Datos Abiertos de Colombia](https://www.datos.gov.co/).

El objetivo es aplicar las capacidades de **procesamiento distribuido de Spark** para limpiar, transformar y analizar un volumen considerable de informaci√≥n sobre mortalidad por suicidio, generando estad√≠sticas √∫tiles y almacenando los resultados procesados para an√°lisis posteriores.

---

## üéØ Objetivos

- Cargar y procesar un conjunto de datos de gran tama√±o desde una fuente p√∫blica.  
- Realizar **limpieza y transformaci√≥n** de datos usando **RDDs o DataFrames**.  
- Ejecutar un **an√°lisis exploratorio (EDA)** para identificar patrones en el tiempo y en los municipios.  
- Almacenar los resultados procesados en formatos **CSV** y **Parquet** para su posterior consumo o visualizaci√≥n.  

---

## üß© Dataset

- **Nombre:** Cantidad de suicidios en Antioquia (2007‚Äì2021)  
- **Fuente:** [Datos Abiertos de Colombia](https://www.datos.gov.co/api/v3/views/db67-sbus/query.json)  
- **Formato:** JSON (descargado v√≠a API REST)  

**Campos principales:**
| Campo | Descripci√≥n |
|--------|--------------|
| `Anio` | A√±o del reporte |
| `NombreRegion` | Subregi√≥n del departamento |
| `NombreMunicipio` | Municipio donde ocurri√≥ el evento |
| `NumeroCasos` | Total de suicidios reportados |
| `NumeroPoblacionObjetivo` | Poblaci√≥n total del municipio (cuando aplica) |


## ‚öôÔ∏è Ejecuci√≥n del Proyecto con Spark (Python)

Sigue estos pasos para ejecutar el procesamiento batch en el entorno local utilizando **Apache Spark** y **Python**.

### üßæ Requisitos previos
- Tener instalado **Python 3.8 o superior**.  
- Tener instalado **Apache Spark** y configuradas las variables de entorno (`SPARK_HOME` y `PATH`).  
- Tener instalado **Java 8 o superior**.  

Puedes verificar las versiones ejecutando:
```bash
python --version
spark-submit --version
java -version 
```

1. Clonar el repositorio
```bash
git clone https://github.com/usuario/spark-batch-suicidios.git
```

2. Moverse a la ruta
```bash
cd batch_spark
```

3. Ejecutar el script
```bash
python spark_batch_suicidios.py
```

Una vez ejecutado, el script generar√° una carpeta con nombre similar a:
output/suicidios_antioquia_batch_20251021_234500/

Dentro encontrar√°s:

- eda_casos_por_anio.csv ‚Üí An√°lisis de casos por a√±o
- eda_casos_por_region.csv ‚Üí An√°lisis de casos por regi√≥n
- eda_causas_mortalidad.csv ‚Üí Causas de mortalidad m√°s frecuentes


## Ejecuci√≥n del Streaming con Spark y Kafka

Este proyecto utiliza **Apache Spark Structured Streaming** para procesar datos en tiempo real provenientes de **Kafka**.

### Requisitos previos

1. Tener **Kafka** y **Zookeeper** corriendo en tu m√°quina virtual.

2. Tener **Python 3.x** y las librer√≠as necesarias instaladas:

   ```bash
   pip install pyspark kafka-python
   ```

3. Aseg√∫rate de que el t√≥pico suicidios_data exista en Kafka:

   ```bash
   kafka-topics.sh --create --topic suicidios_data --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1
   ```

## Pasos para ejecutar

1. Ejecutar el productor de datos
Esto generar√° datos simulados y los enviar√° al t√≥pico de Kafka:

   ```bash
   python3 kafka_producer.py

   ```
Deja esta terminal abierta para que los datos se env√≠en continuamente.

2. Ejecutar el consumidor de Spark Streaming
En otra terminal, ejecuta el script de Spark:

   ```bash
   spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.7 spark_streaming_consumer.py
   ```
- Esto leer√° los datos del t√≥pico suicidios_data.
- Calcular√° estad√≠sticas por pa√≠s y g√©nero cada 1 minuto.
- Mostrar√° los resultados en consola.


